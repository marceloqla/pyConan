import shared_globals
import conan_constants
import random, pickle
import numpy as np
from conan_node import Node
from conan_corr_drcn import DRCN, DRCNWithAntiCorr
from conan_corr_graph import getTumminelloTuple, survivorFixed, survivorFixedWithAntiCorr
import networkx as nx

def nodesFiltering(nodes):
	"""
	From a list of Node objects (defined in conan_node.py, each first created by the conan_aln_helpers.py getNode function)
	filters nodes whose frequencies are above maxfreq or below minfreq user input thresholds

	This is done by selectively adding nodes to a set() structure. Removed are counted for both cases

	Freqlist is generated by freq of property and returned
	"""
	# global msa, maxfreq, minfreq
	freqList = []
	N = len(shared_globals.msa)
	seq = list(shared_globals.msa.items())[0][1]
	newNodes = set()
	removed = [0,0]

	for i,aa in enumerate(seq):
		frequencies = np.zeros(38)
		for sequence in shared_globals.msa.values():
			aa = sequence[i].upper()
			if aa in "ACDEFGHIKLMNPQRSTVWY":
				for propid in conan_constants.setsIdList[aa]:
					frequencies[propid] += 1
		frequencies /= N
		freqList.append(frequencies)

	for node in nodes:
		propid = node.id[0]
		position = node.position[0]
		freq = freqList[position-1][propid]
		if freq > shared_globals.maxfreq:
			removed[0] += 1
			continue
		elif freq < shared_globals.minfreq:
			removed[1] += 1
			continue
		else:
			newNodes.add(node)

	return (newNodes,removed,freqList)
	
def getNodes():
	"""
	Creates Node (defined in conan_node.py) objects if positions has AA
	Nodes are identified by residue type or property + column position
	A set() object is returned
	"""
	# global msa
	nodeSet = set()
	if shared_globals.marginal == 1:
		for sequence in shared_globals.msa.values():
			for i,aa in enumerate(sequence):
				if aa in "ACDEFGHIKLMNPQRSTVWY":
					pos = i+1
					for v in conan_constants.setsIdList[aa]:
						node = Node(v,pos)
						nodeSet.add(node)
	else:
		for sequence in shared_globals.msa.values():
			for i,aa in enumerate(sequence):
				if aa in "ACDEFGHIKLMNPQRSTVWY":
					node = Node(conan_constants.setsIdList[aa][0],i+1)
					nodeSet.add(node)

	return nodeSet

#
# Network Generation Functions
#
def genCorrelationNetwork(method,netthr,freqList):
	"""
	Generates and returns a list of correlated nodes (node1, node2, pvalue, jaccard) from user input options and a msa
	A frequency list for given nodes and pvalue threshold (netthr) is also supplied to this function
	"""
	# global nodes
	N = len(shared_globals.nodes)
	nodeList = list(shared_globals.nodes)
	network = []
	tummineloDic = {}
	#temp = 0

	for i in range(0,N-1):
		print("Calculating Correlations... (" + str(i) + "/" + str(N) + ")")
		for j in range(i+1,N):
			n1 = nodeList[i]#Object
			n2 = nodeList[j]#Object
			jc = 0.0

			fr1 = freqList[n1.getIndex()][n1.id][0]
			fr2 = freqList[n2.getIndex()][n2.id][0]
			if n1.position != n2.position and abs(fr1-fr2) <= conan_constants.FREQ_WINDOW:
				#temp+=1
				if method == 1:
					w,jc = DRCN(n1,n2)
				else:		
					w = 0.0
					tummData,jc = getTumminelloTuple(n1,n2)
					if tummData in tummineloDic:
						w = tummineloDic[tummData]
					else:
						w = survivorFixed(tummData[0]-1,len(shared_globals.msa),tummData[1],tummData[2])*-1
						tummineloDic[tummData] = w

				if w >= netthr:
					#print(str(temp) + " " + n1.toString() + " " + n2.toString() + " " + str(w))
					network.append((n1,n2,w,jc))

	network = sorted(network,key=lambda x: x[2],reverse=True)
	if len(network) > 100000:
		network = network[0:100000]
	return network

def genCorrelationNetworkWithAntiCorr(method,netthr,freqList):
	"""
	Generates and returns a list of correlated nodes (node1, node2, pvalue, jaccard) from user input options and a msa
	A frequency list for given nodes and pvalue threshold (netthr) is also supplied to this function
	#NEW: AntiCorr added
	"""
	# global nodes

	N = len(shared_globals.nodes)
	nodeList = list(shared_globals.nodes)
	network = []
	#NEW: anticorr network also created with fdiff var - 2
	antinetwork = []
	fdiff = 0.0
	tummineloDic = {}

	for i in range(0,N-1):
		print("Calculating Correlations... (" + str(i) + "/" + str(N) + ")")
		for j in range(i+1,N):
			n1 = nodeList[i]#Object
			n2 = nodeList[j]#Object
			jc = 0.0
			anti = False
			fr1 = freqList[n1.getIndex()][n1.id][0]
			fr2 = freqList[n2.getIndex()][n2.id][0]
			#NEW: fdiff var - 1
			fdiff = 0.0
			#correlation pvalue is calculated if residues are not in the same col and frequency absolute diff is bigger than set in constants
			if n1.position != n2.position and abs(fr1-fr2) <= conan_constants.FREQ_WINDOW:
				#method one is DRCN
				if method == 1:
					#OLD - 1:
					# w,jc = DRCN(n1,n2)

					#NEW frequency difference also outputted - 1: 
					w,jc, fdiff = DRCNWithAntiCorr(n1,n2)
				#other method is tumminelo, each calculated pvalue is saved in tummineloDic
				else:		
					w = 0.0
					tummData,jc = getTumminelloTuple(n1,n2)
					# print("tummData")
					# print(tummData)
					if tummData in tummineloDic:
						w = tummineloDic[tummData]
					else:
						#OLD - 1:
						# w = survivorFixed(tummData[0]-1,len(msa),tummData[1],tummData[2])*-1

						#NEW frequency difference also outputted - 1:
						# print("tummData")
						# print(tummData)
						# print(len(shared_globals.msa))
						w, fdiff = survivorFixedWithAntiCorr(tummData[0]-1,len(shared_globals.msa),tummData[1],tummData[2])
						w = w * -1
						tummineloDic[tummData] = w
				
				#correlations are then thresholded against the netthr p-value cutoff

				#OLD - 2:
				# if w >= netthr: 
					# network.append((n1,n2,w,jc))

				#NEW - 4: 
				if w >= netthr and fdiff > 0:
					network.append((n1,n2,w,jc))
				elif w >= netthr and fdiff < 0:
					antinetwork.append((n1,n2,w,jc))
	#network maximum edges = 100000
	network = sorted(network,key=lambda x: x[2],reverse=True)
	if len(network) > 100000:
		print("WARNING: Resulting Correlation network has more than 100.000 Edges.")
		print("WARNING: Only 100.000 Edges will be retained (Selection. Criteria: smaller P-values).")
		network = network[0:100000]
	#OLD - 1:
	# return network

	#NEW: anticorr network limiting - 4
	#antinetwork maximum edges = 100000
	antinetwork = sorted(antinetwork,key=lambda x: x[2],reverse=True)
	if len(antinetwork) > 100000:
		print("WARNING: Resulting Anti-Correlation network has more than 100.000 Edges.")
		print("WARNING: Only 100.000 Edges will be retained (Selection. Criteria: smaller P-values).")
		antinetwork = antinetwork[0:100000]
	#NEW: anticorr network also outputted - 1
	return network, antinetwork

def getNodeFrequency(node, mode="freq"):
	"""
	WARN: Unused in Old, now used
	Returns frequency for a given node object
	"""
	# global msa
	aa_list = conan_constants.setsAA[node.id[0]]
	i = node.position[0]-1
	freq = 0.0
	for sequence in shared_globals.msa.values():
		if sequence[i] in aa_list:
			freq += 1.0
	if mode == "freq":
		return float(freq)/float(len(shared_globals.msa))
	return freq

def getNodeCoFrequency(node1, node2, mode="freq"):
	"""
	Returns frequency of node1 given node2 objects
	"""
	# global msa
	aa_list1 = conan_constants.setsAA[node1.id[0]]
	aa_list2 = conan_constants.setsAA[node2.id[0]]
	i1 = node1.position[0]-1
	i2 = node2.position[0]-1
	cofreq = 0.0
	for sequence in shared_globals.msa.values():
		if sequence[i1] in aa_list1:
			if sequence[i2] in aa_list2:
				cofreq += 1.0
	if mode == "freq":
		return float(cofreq)/float(len(shared_globals.msa))
	return cofreq
	

def pickColor(commIndex):
	"""
	WARN: Unused
	Returns RGB formatted colors for each generated community
	"""
	colors = ["#9180ff","#7fffa1","#fffbbf","#ff80b3","#bffff2","#ffee00","#c8bfff","#ff2200","#4100f2","#81f200","#ffaa00","#ffbfbf","#3d9df2","#917399","#992654","#822699","#94994d","#258c00","#8c0000","#8c5e00"]
	if commIndex < len(colors):
		return colors[commIndex]
	else:
		r = lambda: random.randint(0,255)
		return '#%02X%02X%02X' % (r(),r(),r())


def filterNodesPriori(Gnx):
	"""
	WARN: Unused and Unfinished?
	Apparently filters Nodes in a network (Gnx) removing Nodes in the same column which are already represented
	by alphabet reduction groups in the same column
	"""
	for Ni in Gnx.nodes():
		if Ni in Gnx.nodes():
			neighbors = Gnx.neighbors(Ni)
			neighDic = {}
			neighDic[Ni.position[0]] = [Ni.id[0]]

			for node in neighbors:
				aaid = node.id[0]
				pos = node.position[0]
				if pos in neighDic:
					neighDic[pos].append(aaid)
				else:
					neighDic[pos] = [aaid]

			for pos, aaidList in neighDic.items():
				if len(aaidList) > 1:
					minsize = 999
					bestaaid = []
					for aaid in aaidList:
						value = len(conan_constants.setsAA[aaid])
						if value < minsize:
							bestaaid = [aaid]
							minsize = value
						elif value == minsize:
							bestaaid.append(aaid)
					for aaid in aaidList:
						if aaid not in bestaaid:
							node = Node(aaid,pos)
							Gnx.remove_node(node)
	return Gnx

def merge_nodes(G,nodes, new_node, attr_dict=None, **attr):
	"""
	WARN: Unused and Unfinished?

	Unknown objective but should merge two nodes in a network
	"""
	G.add_node(new_node, attr_dict, **attr) # Add the 'merged' node

	for n1,n2,data in G.edges(data=True):
		if n1 in nodes:
			G.add_edge(new_node,n2,data)
		elif n2 in nodes:
			G.add_edge(n1,new_node,data)

	for n in nodes: # remove the merged nodes
		G.remove_node(n)

def communityDetection2(Gnx):
	"""
	WARN: Unused and Unfinished?

	Creates residue communities by networkx connected_component_subgraphs function and jaccard coefficient 
	"""
	communities = []
	count = 0
	components = nx.connected_component_subgraphs(Gnx)
	jc_all = 0.0
	N = 0.0

	for comp in components:
		Nedges = len(comp.edges())
		if Nedges > 0:
			jc_comm = 0.0
			for ni,nj in comp.edges():
				jc_comm += Gnx[ni][nj]['weight']
			jc_comm /= Nedges
			if jc_comm >= conan_constants.MIN_JC:
				communities.append(comp.nodes())
				N += 1.0
				jc_all += jc_comm
	if N == 0.0:
		return 0.0,[],0.0
	jc_all /= N

	return N,communities,jc_all

def filterRedundancy(comm):
	"""
	Merges Residues into Properties in a same community
	Returns communities without Residue-Property redundancy

	Properties with a higher number of gruped aminoacids are preferentialy kept in relation to others
	"""
	new_comm = set()
	positions = {}

	for node in comm:
		aa2_id,pos = node.getTuple()
		if pos in positions:
			aa_id = positions[pos]
			aa = conan_constants.properties[aa_id]
			aa2 = conan_constants.properties[aa2_id]
			size1 = conan_constants.alphabet[aa]
			size2 = conan_constants.alphabet[aa2]
			if size2 < size1:
				positions[pos] = aa2_id
		else:
			positions[pos] = aa2_id

	for pos,aa_id in positions.items():
		residue = Node(aa_id,pos)
		new_comm.add(residue)
	return new_comm

def filterNetwork(Gnx,comms):
	"""
	WARN: Unused
	Removes Nodes from Network if not in Communities
	Returns trimmed network
	"""
	comm_nodes = set()

	for comm in comms:
		comm_nodes = comm_nodes.union(comm)
	for node in Gnx.nodes():
		if node not in comm_nodes:
			Gnx.remove_node(node)
	return Gnx

def correctedNresidues(comms):
	"""
	Calculates number of unique Nodes in communities with 2+ residues
	"""
	comm_nodes = set()

	for comm in comms:
		if len(comm) > 1:
			comm_nodes = comm_nodes.union(comm)

	return len(comm_nodes)

def getJacardCoeficient(res1,res2):
	"""
	Returns Jacard Coeficient between two residue Node objects
	Jacard Coeficient is interseccion of two Sets divided by union of two Sets

	B|A divided by AUB

	OR

	B|A divided by A+B-B|A

	Note that for sets delimited by two residues this overlap might be skewed. E.g.
	MSA        Count Perc
	All        10000 100%
	Set 1       2000 20%
	Set 2       1000 10%
	Set 2|Set 1  999 9.99%

	Jaccard = 999/2000+1000-999 = 0.4992 or 49.92%
	But Set 2 overlap to Set 1 is = 999/1000 = 0.999 or 99.9%
	Whilst Set 1 overlap to Set 2 is = 999/2000 = 0.4995 or 49.95% 
	"""
	# global msa
	aa1_list = conan_constants.setsAA[res1.id[0]]
	i1 = res1.position[0] - 1
	aa2_list = conan_constants.setsAA[res2.id[0]]
	i2 = res2.position[0] - 1
	a = 0.0
	b = 0.0
	c = 0.0
	d = 0.0

	for sequence in shared_globals.msa.values():
		if sequence[i1].upper() in aa1_list:
			if sequence[i2].upper() in aa2_list:
				a += 1.0
			else:
				b += 1.0
		elif sequence[i2].upper() in aa2_list:
			c += 1.0
		else:
			d += 1.0

	jc = a / (a + b + c)
	return jc

def getFullJacardCoefficient(Gnx,communities,extra_edgesJC):
	"""
	Returns Average Jacard Coeficient calculated for each residue community (see also above)
	and
	a "minimum" Jacard Coefficient value which is 1.0 (max value) or the same as the Average Jacard Coeficient
	"""
	minJC = 1.0
	avgJC = 0.0

	for comm in communities:
		avgCommJC = 0.0
		NcommJC = 0.0
		comm = list(comm)
		for i in range(0,len(comm)-1):
			for j in range(i+1,len(comm)):
				res1 = comm[i]
				res2 = comm[j]
				NcommJC += 1.0
				if res1 in Gnx[res2]:
					avgCommJC += Gnx[res1][res2]['weight']
				else:
					if res1 < res2:
						if (res1,res2) in extra_edgesJC:
							avgCommJC += extra_edgesJC[(res1,res2)]
						else:
							value = getJacardCoeficient(res1, res2)
							extra_edgesJC[(res1, res2)] = value
							avgCommJC += value
					else:
						if (res2,res1) in extra_edgesJC:
							avgCommJC += extra_edgesJC[(res2, res1)]
						else:
							value = getJacardCoeficient(res1,res2)
							extra_edgesJC[(res2,res1)] = value
							avgCommJC += value
		avgCommJC /= NcommJC
		avgJC += avgCommJC
		if avgCommJC < minJC:
			minJC = avgCommJC
	avgJC /= float(len(communities))
	return avgJC,minJC


def writeCommunities(path,communities):
	"""
	Outputs each Comm in communities array to a file in the given path
	"""
	communities = sorted(communities,key=lambda x: len(x),reverse=True)
	fw1 = open(path,'w')
	for comm in communities:
		if len(comm) > 1:
			for node in comm:
				fw1.write(node.toStackedString() + " ")
			fw1.write("\n")
	fw1.close()

def writeBackbone(path,backbone):
	"""
	Outputs backbone to path
	"""
	fw2 = open(path,'w')
	for ni,nj in backbone.edges():
		w = backbone[ni][nj]['weight']
		pv = backbone[ni][nj]['pvalue']
		fw2.write(ni.toStackedString() + " " + nj.toStackedString() + " " + str(w)  + " " + str(pv) + "\n")
	fw2.close()

def writeFullnetwork(path,net):
	"""
	Outputs full network to path
	"""
	fw2 = open(path,'w')
	for ni,nj,pv,jc in net:
		fw2.write(ni.toStackedString() + " " + nj.toStackedString() + " " + str(pv)  + " " + str(jc) + "\n")
	fw2.close()

def writeSeqmodeNetwork(path, network, antinetwork):
	"""
	Outputs network and antinetwork to path
	"""
	# global msa
	fw2 = open(path,'w')
	#write msa seq count
	# fw2.write("ni" + " " + "nj"+ " " + "jc"  + " " + str(pv) + "\n")
	for (ni,nj,w,jc) in network:
		fi = getNodeFrequency(ni, mode="count")
		fj = getNodeFrequency(nj, mode="count")
		fij = getNodeCoFrequency(ni, nj, mode="count")
		fji = getNodeCoFrequency(nj, ni, mode="count")
		fw2.write(ni.toStackedString() + " " + nj.toStackedString() + " " + str(fi) + " " + str(fj) + " " + str(fij) + " " + str(fji) + " " + str(w)  + " " + str(jc) + "\n")
	for (ni,nj,w,jc) in antinetwork:
		fi = getNodeFrequency(ni, mode="count")
		fj = getNodeFrequency(nj, mode="count")
		fij = getNodeCoFrequency(ni, nj, mode="count")
		fji = getNodeCoFrequency(nj, ni, mode="count")
		fw2.write(ni.toStackedString() + " " + nj.toStackedString() + " " + str(fi) + " " + str(fj) + " " + str(fij) + " " + str(fji) + " " + str(w)  + " " + str(jc) + "\n")
	fw2.close()

def compareConfigsAndLoad(outputdir, prefiltered_network_full_name, inputfile,method,netthr,jcthr,min_pv,anticorr,seqmode,seqmutmode):
	"""
	Verifies if previous run settings are the same of this session.
	If not, returns False for Network and False for Antinetwork
	If yes, uses pickle to load previously calculated network
	"""
	fi2 = open(prefiltered_network_full_name, "r")
	loadedconfigs = fi2.readlines()
	loadedconfigs = [a.rstrip("\n") for a in loadedconfigs]
	prevMIN_JC = loadedconfigs.pop(0)
	prevFREQ_WINDOW = loadedconfigs.pop(0)
	prevCD_HIT_PATH = loadedconfigs.pop(0)
	prevMIN_CORR_FREQ = loadedconfigs.pop(0)
	prevMIN_CORR_COUNT = loadedconfigs.pop(0)
	if prevMIN_JC != str(conan_constants.MIN_JC):
		print("Divergence in constant MIN_JC to previous run... Recalculating network...")
		return False, False
	if prevFREQ_WINDOW != str(conan_constants.FREQ_WINDOW):
		print("Divergence in constant FREQ_WINDOW to previous run... Recalculating network...")
		return False, False
	if prevCD_HIT_PATH != str(conan_constants.CD_HIT_PATH):
		print("Divergence in constant CD_HIT_PATH to previous run... Recalculating network...")
		return False, False
	if prevMIN_CORR_FREQ != str(conan_constants.MIN_CORR_FREQ):
		print("Divergence in constant MIN_CORR_FREQ to previous run... Recalculating network...")
		return False, False
	if prevMIN_CORR_COUNT != str(conan_constants.MIN_CORR_COUNT):
		print("Divergence in constant MIN_CORR_COUNT to previous run... Recalculating network...")
		return False, False
	previnputfile = loadedconfigs.pop(0)
	prevoutputdir = loadedconfigs.pop(0)
	prevminocc = loadedconfigs.pop(0)
	prevmaxid = loadedconfigs.pop(0)
	prevminfreq = loadedconfigs.pop(0)
	prevmaxfreq = loadedconfigs.pop(0)
	prevmethod = loadedconfigs.pop(0)
	prevnetthr = loadedconfigs.pop(0)
	prevjcthr = loadedconfigs.pop(0)
	prevmarginal = loadedconfigs.pop(0)
	prevmin_pv = loadedconfigs.pop(0)
	prevanticorr = loadedconfigs.pop(0)
	prevseqmode = loadedconfigs.pop(0)
	prevseqmutmode = loadedconfigs.pop(0)
	if previnputfile != str(inputfile):
		print("Divergence in variable inputfile to previous run... Recalculating network...")
		return False, False
	if prevoutputdir != str(outputdir):
		print("Divergence in variable outputdir to previous run... Recalculating network...")
		return False, False
	if prevminocc != str(shared_globals.minocc):
		print("Divergence in variable shared_globals.minocc to previous run... Recalculating network...")
		return False, False
	if prevmaxid != str(shared_globals.maxid):
		print("Divergence in variable shared_globals.maxid to previous run... Recalculating network...")
		return False, False
	if prevminfreq != str(shared_globals.minfreq):
		print("Divergence in variable shared_globals.minfreq to previous run... Recalculating network...")
		return False, False
	if prevmaxfreq != str(shared_globals.maxfreq):
		print("Divergence in variable shared_globals.maxfreq to previous run... Recalculating network...")
		return False, False
	if prevmethod != str(method):
		print("Divergence in variable method to previous run... Recalculating network...")
		return False, False
	if prevnetthr != str(netthr):
		print("Divergence in variable netthr to previous run... Recalculating network...")
		return False, False
	if prevjcthr != str(jcthr):
		print("Divergence in variable jcthr to previous run... Recalculating network...")
		return False, False
	if prevmarginal != str(shared_globals.marginal):
		print("Divergence in variable shared_globals.marginal to previous run... Recalculating network...")
		return False, False
	if prevmin_pv != str(min_pv):
		print("Divergence in variable min_pv to previous run... Recalculating network...")
		return False, False
	if prevanticorr != str(anticorr):
		print("Divergence in variable anticorr to previous run... Recalculating network...")
		return False, False
	if prevseqmode != str(seqmode):
		print("Divergence in variable seqmode to previous run... Recalculating network...")
		return False, False
	if prevseqmutmode != str(seqmutmode):
		print("Divergence in variable seqmutmode to previous run... Recalculating network...")
		return False, False
	filehandler_network = open(outputdir+'/network.pickle', 'rb')
	network = pickle.load(filehandler_network)
	filehandler_network.close()
	filehandler_antinetwork = open(outputdir+'/antinetwork.pickle', 'rb')
	antinetwork = pickle.load(filehandler_antinetwork)
	filehandler_antinetwork.close()
	return network, antinetwork
	

def writeOutNetworks(outputdir, prefiltered_network_full_name, network, antinetwork, inputfile,method,netthr,jcthr,min_pv,anticorr,seqmode,seqmutmode):
	"""
	Writes out a configuration file for current session as .txt
	And two pickle files, one for network, other for antinetwork
	"""
	fo2 = open(prefiltered_network_full_name, "w")
	fo2.write(str(conan_constants.MIN_JC) + "\n")
	fo2.write(str(conan_constants.FREQ_WINDOW) + "\n")
	fo2.write(str(conan_constants.CD_HIT_PATH) + "\n")
	fo2.write(str(conan_constants.MIN_CORR_FREQ) + "\n")
	fo2.write(str(conan_constants.MIN_CORR_COUNT) + "\n")
	fo2.write(str(inputfile) + "\n")
	fo2.write(str(outputdir) + "\n")
	fo2.write(str(shared_globals.minocc) + "\n")
	fo2.write(str(shared_globals.maxid) + "\n")
	fo2.write(str(shared_globals.minfreq) + "\n")
	fo2.write(str(shared_globals.maxfreq) + "\n")
	fo2.write(str(method) + "\n")
	fo2.write(str(netthr) + "\n")
	fo2.write(str(jcthr) + "\n")
	fo2.write(str(shared_globals.marginal) + "\n")
	fo2.write(str(min_pv) + "\n")
	fo2.write(str(anticorr) + "\n")
	fo2.write(str(seqmode) + "\n")
	fo2.write(str(seqmutmode) + "\n")
	fo2.close()
	filehandler_dnetwork = open(outputdir+'/network.pickle', 'wb')
	pickle.dump(network, filehandler_dnetwork, protocol=3)
	filehandler_dnetwork.close()
	filehandler_danetwork = open(outputdir+'/antinetwork.pickle', 'wb')
	pickle.dump(antinetwork, filehandler_danetwork, protocol=3)
	filehandler_danetwork.close()
